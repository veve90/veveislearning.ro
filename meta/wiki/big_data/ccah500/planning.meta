a:2:{s:7:"current";a:9:{s:4:"date";a:2:{s:7:"created";i:1448127309;s:8:"modified";i:1448228289;}s:7:"creator";s:13:"Alina GHERMAN";s:4:"user";s:4:"veve";s:11:"last_change";a:7:{s:4:"date";i:1448228289;s:2:"ip";s:13:"154.52.129.35";s:4:"type";s:1:"E";s:2:"id";s:30:"wiki:big_data:ccah500:planning";s:4:"user";s:4:"veve";s:3:"sum";s:162:"[Network Topologies: understand network usage in Hadoop (for both HDFS and MapReduce) and propose or identify key network design components for a given scenario] ";s:5:"extra";s:0:"";}s:11:"contributor";a:1:{s:4:"veve";s:13:"Alina GHERMAN";}s:5:"title";s:32:"3. Hadoop Cluster Planning (16%)";s:11:"description";a:2:{s:15:"tableofcontents";a:9:{i:0;a:4:{s:3:"hid";s:26:"hadoop_cluster_planning_16";s:5:"title";s:32:"3. Hadoop Cluster Planning (16%)";s:4:"type";s:2:"ul";s:5:"level";i:1;}i:1;a:4:{s:3:"hid";s:61:"choosing_the_hardware_and_the_os_on_the_apache_hadoop_cluster";s:5:"title";s:62:"Choosing the hardware and the OS on the Apache Hadoop cluster.";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:2;a:4:{s:3:"hid";s:38:"analyze_the_choices_in_selecting_an_os";s:5:"title";s:38:"Analyze the choices in selecting an OS";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:3;a:4:{s:3:"hid";s:42:"understand_kernel_tuning_and_disk_swapping";s:5:"title";s:42:"Understand kernel tuning and disk swapping";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:4;a:4:{s:3:"hid";s:99:"given_a_scenario_and_workload_pattern_identify_a_hardware_configuration_appropriate_to_the_scenario";s:5:"title";s:100:"Given a scenario and workload pattern, identify a hardware configuration appropriate to the scenario";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:5;a:4:{s:3:"hid";s:105:"given_a_scenario_determine_the_ecosystem_components_your_cluster_needs_to_run_in_order_to_fulfill_the_sla";s:5:"title";s:106:"Given a scenario, determine the ecosystem components your cluster needs to run in order to fulfill the SLA";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:6;a:4:{s:3:"hid";s:135:"cluster_sizinggiven_a_scenario_and_frequency_of_execution_identify_the_specifics_for_the_workload_including_cpu_memory_storage_disk_i_o";s:5:"title";s:142:"Cluster sizing: given a scenario and frequency of execution, identify the specifics for the workload, including CPU, memory, storage, disk I/O";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:7;a:4:{s:3:"hid";s:118:"disk_sizing_and_configuration_including_jbod_versus_raid_sans_virtualization_and_disk_sizing_requirements_in_a_cluster";s:5:"title";s:122:"Disk Sizing and Configuration, including JBOD versus RAID, SANs, virtualization, and disk sizing requirements in a cluster";s:4:"type";s:2:"ul";s:5:"level";i:2;}i:8;a:4:{s:3:"hid";s:155:"network_topologiesunderstand_network_usage_in_hadoop_for_both_hdfs_and_mapreduce_and_propose_or_identify_key_network_design_components_for_a_given_scenario";s:5:"title";s:159:"Network Topologies: understand network usage in Hadoop (for both HDFS and MapReduce) and propose or identify key network design components for a given scenario";s:4:"type";s:2:"ul";s:5:"level";i:2;}}s:8:"abstract";s:260:"3. Hadoop Cluster Planning (16%)

Choosing the hardware and the OS on the Apache Hadoop cluster.

  - Slave Nodes: Data Nodes and NodeManager nodes

	*  Enable hyper-threading, quickPath
			*  usualy disk and network IO bound
			*  usualy one map /reduce = 2-4";}s:8:"internal";a:2:{s:5:"cache";b:1;s:3:"toc";b:1;}s:8:"relation";a:1:{s:10:"firstimage";s:0:"";}}s:10:"persistent";a:5:{s:4:"date";a:2:{s:7:"created";i:1448127309;s:8:"modified";i:1448228289;}s:7:"creator";s:13:"Alina GHERMAN";s:4:"user";s:4:"veve";s:11:"last_change";a:7:{s:4:"date";i:1448228289;s:2:"ip";s:13:"154.52.129.35";s:4:"type";s:1:"E";s:2:"id";s:30:"wiki:big_data:ccah500:planning";s:4:"user";s:4:"veve";s:3:"sum";s:162:"[Network Topologies: understand network usage in Hadoop (for both HDFS and MapReduce) and propose or identify key network design components for a given scenario] ";s:5:"extra";s:0:"";}s:11:"contributor";a:1:{s:4:"veve";s:13:"Alina GHERMAN";}}}